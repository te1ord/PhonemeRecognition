{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T19:26:37.272486Z",
     "iopub.status.busy": "2025-04-02T19:26:37.272124Z",
     "iopub.status.idle": "2025-04-02T19:26:37.399277Z",
     "shell.execute_reply": "2025-04-02T19:26:37.398599Z",
     "shell.execute_reply.started": "2025-04-02T19:26:37.272389Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T19:26:37.400826Z",
     "iopub.status.busy": "2025-04-02T19:26:37.400553Z",
     "iopub.status.idle": "2025-04-02T19:26:37.404894Z",
     "shell.execute_reply": "2025-04-02T19:26:37.404119Z",
     "shell.execute_reply.started": "2025-04-02T19:26:37.400784Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "timit_path = '/kaggle/input/darpa-timit-acousticphonetic-continuous-speech/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T19:26:37.406248Z",
     "iopub.status.busy": "2025-04-02T19:26:37.406037Z",
     "iopub.status.idle": "2025-04-02T19:26:37.417360Z",
     "shell.execute_reply": "2025-04-02T19:26:37.416516Z",
     "shell.execute_reply.started": "2025-04-02T19:26:37.406220Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_path = '/kaggle/input/darpa-timit-acousticphonetic-continuous-speech/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T19:26:37.420054Z",
     "iopub.status.busy": "2025-04-02T19:26:37.419586Z",
     "iopub.status.idle": "2025-04-02T19:26:37.656491Z",
     "shell.execute_reply": "2025-04-02T19:26:37.655825Z",
     "shell.execute_reply.started": "2025-04-02T19:26:37.420009Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat(\n",
    "    objs=[\n",
    "        pd.read_csv(os.path.join(timit_path, 'train_data.csv'), index_col=0),\n",
    "        pd.read_csv(os.path.join(timit_path, 'test_data.csv'), index_col=0)\n",
    "    ]\n",
    ")\n",
    "\n",
    "df = df[\n",
    "    (df['is_converted_audio'] == False) \n",
    "    ].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T19:26:37.657942Z",
     "iopub.status.busy": "2025-04-02T19:26:37.657634Z",
     "iopub.status.idle": "2025-04-02T19:26:37.680658Z",
     "shell.execute_reply": "2025-04-02T19:26:37.679865Z",
     "shell.execute_reply.started": "2025-04-02T19:26:37.657903Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25200, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>test_or_train</th>\n",
       "      <th>dialect_region</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>path_from_data_dir</th>\n",
       "      <th>path_from_data_dir_windows</th>\n",
       "      <th>is_converted_audio</th>\n",
       "      <th>is_audio</th>\n",
       "      <th>is_word_file</th>\n",
       "      <th>is_phonetic_file</th>\n",
       "      <th>is_sentence_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SI1311.PHN</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SI1311.PHN</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.PHN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SI1311.WRD</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SI1311.WRD</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.WRD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SX321.PHN</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SX321.PHN</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SX321.PHN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SX321.WRD</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SX321.WRD</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SX321.WRD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SI681.TXT</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SI681.TXT</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SI681.TXT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index test_or_train dialect_region speaker_id    filename  \\\n",
       "0    2.0         TRAIN            DR4      MMDM0  SI1311.PHN   \n",
       "1    3.0         TRAIN            DR4      MMDM0  SI1311.WRD   \n",
       "2    4.0         TRAIN            DR4      MMDM0   SX321.PHN   \n",
       "3    5.0         TRAIN            DR4      MMDM0   SX321.WRD   \n",
       "4    6.0         TRAIN            DR4      MMDM0   SI681.TXT   \n",
       "\n",
       "           path_from_data_dir     path_from_data_dir_windows  \\\n",
       "0  TRAIN/DR4/MMDM0/SI1311.PHN  TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.PHN   \n",
       "1  TRAIN/DR4/MMDM0/SI1311.WRD  TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.WRD   \n",
       "2   TRAIN/DR4/MMDM0/SX321.PHN   TRAIN\\\\DR4\\\\MMDM0\\\\SX321.PHN   \n",
       "3   TRAIN/DR4/MMDM0/SX321.WRD   TRAIN\\\\DR4\\\\MMDM0\\\\SX321.WRD   \n",
       "4   TRAIN/DR4/MMDM0/SI681.TXT   TRAIN\\\\DR4\\\\MMDM0\\\\SI681.TXT   \n",
       "\n",
       "  is_converted_audio is_audio is_word_file is_phonetic_file is_sentence_file  \n",
       "0              False    False        False             True            False  \n",
       "1              False    False         True            False            False  \n",
       "2              False    False        False             True            False  \n",
       "3              False    False         True            False            False  \n",
       "4              False    False        False            False             True  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T19:26:37.682175Z",
     "iopub.status.busy": "2025-04-02T19:26:37.681896Z",
     "iopub.status.idle": "2025-04-02T19:26:37.690158Z",
     "shell.execute_reply": "2025-04-02T19:26:37.689286Z",
     "shell.execute_reply.started": "2025-04-02T19:26:37.682138Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TRAIN    18480\n",
       "TEST      6720\n",
       "Name: test_or_train, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['test_or_train'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T19:26:37.691740Z",
     "iopub.status.busy": "2025-04-02T19:26:37.691366Z",
     "iopub.status.idle": "2025-04-02T19:26:37.712163Z",
     "shell.execute_reply": "2025-04-02T19:26:37.711306Z",
     "shell.execute_reply.started": "2025-04-02T19:26:37.691708Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio/Phonemes/Words existence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3360, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phoneme_present_df = df[df['is_phonetic_file'].fillna(False)]\n",
    "phoneme_present_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6300, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_present = df[df['is_word_file'].fillna(False)]\n",
    "word_present.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6300, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_present_df = df[df['is_audio'].fillna(False)]\n",
    "audio_present_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Form audio-phonemes-words groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe94e3b4cb747bbbb909afc70870269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = {}\n",
    "\n",
    "for idx, row in tqdm(df.iterrows()):\n",
    "    path = row['path_from_data_dir']\n",
    "    entry_id = path.split('.')[0]\n",
    "    \n",
    "\n",
    "    if entry_id not in data:\n",
    "        data[entry_id] = {}\n",
    "\n",
    "    if row['is_audio'] is True:\n",
    "        data[entry_id]['audio_file'] = os.path.join(data_path, path)\n",
    "    elif row['is_word_file'] is True:\n",
    "        data[entry_id]['word_file'] = os.path.join(data_path, path)\n",
    "    elif row['is_phonetic_file'] is True:\n",
    "        data[entry_id]['phonetic_file'] = os.path.join(data_path, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3360, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>test_or_train</th>\n",
       "      <th>dialect_region</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>path_from_data_dir</th>\n",
       "      <th>path_from_data_dir_windows</th>\n",
       "      <th>is_converted_audio</th>\n",
       "      <th>is_audio</th>\n",
       "      <th>is_word_file</th>\n",
       "      <th>is_phonetic_file</th>\n",
       "      <th>is_sentence_file</th>\n",
       "      <th>entry_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SI1311.PHN</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SI1311.PHN</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.PHN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SI1311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SX321.PHN</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SX321.PHN</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SX321.PHN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SX321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SX51.PHN</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SX51.PHN</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SX51.PHN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SX51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>13.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SX231.PHN</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SX231.PHN</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SX231.PHN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SX231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>19.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SX141.PHN</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SX141.PHN</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SX141.PHN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SX141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index test_or_train dialect_region speaker_id    filename  \\\n",
       "0        0    2.0         TRAIN            DR4      MMDM0  SI1311.PHN   \n",
       "1        2    4.0         TRAIN            DR4      MMDM0   SX321.PHN   \n",
       "2        6    9.0         TRAIN            DR4      MMDM0    SX51.PHN   \n",
       "3        9   13.0         TRAIN            DR4      MMDM0   SX231.PHN   \n",
       "4       14   19.0         TRAIN            DR4      MMDM0   SX141.PHN   \n",
       "\n",
       "           path_from_data_dir     path_from_data_dir_windows  \\\n",
       "0  TRAIN/DR4/MMDM0/SI1311.PHN  TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.PHN   \n",
       "1   TRAIN/DR4/MMDM0/SX321.PHN   TRAIN\\\\DR4\\\\MMDM0\\\\SX321.PHN   \n",
       "2    TRAIN/DR4/MMDM0/SX51.PHN    TRAIN\\\\DR4\\\\MMDM0\\\\SX51.PHN   \n",
       "3   TRAIN/DR4/MMDM0/SX231.PHN   TRAIN\\\\DR4\\\\MMDM0\\\\SX231.PHN   \n",
       "4   TRAIN/DR4/MMDM0/SX141.PHN   TRAIN\\\\DR4\\\\MMDM0\\\\SX141.PHN   \n",
       "\n",
       "  is_converted_audio is_audio is_word_file is_phonetic_file is_sentence_file  \\\n",
       "0              False    False        False             True            False   \n",
       "1              False    False        False             True            False   \n",
       "2              False    False        False             True            False   \n",
       "3              False    False        False             True            False   \n",
       "4              False    False        False             True            False   \n",
       "\n",
       "                 entry_id  \n",
       "0  TRAIN/DR4/MMDM0/SI1311  \n",
       "1   TRAIN/DR4/MMDM0/SX321  \n",
       "2    TRAIN/DR4/MMDM0/SX51  \n",
       "3   TRAIN/DR4/MMDM0/SX231  \n",
       "4   TRAIN/DR4/MMDM0/SX141  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in a matter of correct counting enable only phonemes file as each row can be any of audio/word/phonetics file with same speakers/dialects\n",
    "\n",
    "df_phonemes = df[\n",
    "    (df['is_converted_audio'] == False) & \\\n",
    "    (df['is_phonetic_file'] == True)\n",
    "    ].reset_index()\n",
    "\n",
    "print(df_phonemes.shape)\n",
    "df_phonemes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_phonemes[df_phonemes['test_or_train'] == 'TRAIN'].copy()\n",
    "df_test = df_phonemes[df_phonemes['test_or_train'] == 'TEST'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speakers Intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_speakers = set(df_train['speaker_id'].unique())\n",
    "test_speakers = set(df_test['speaker_id'].unique())\n",
    "\n",
    "train_speakers & test_speakers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dialects Intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dialects: {'DR3', 'DR4', 'DR2'}\n",
      "test_dialects: {'DR2', 'DR1', 'DR7', 'DR6', 'DR5', 'DR3', 'DR8', 'DR4'}\n",
      "\n",
      "train_dialects & test_dialects: {'DR3', 'DR4', 'DR2'}\n",
      "test_dialects - train_dialects: {'DR1', 'DR6', 'DR7', 'DR8', 'DR5'}\n"
     ]
    }
   ],
   "source": [
    "train_dialects = set(df_train['dialect_region'].unique())\n",
    "test_dialects = set(df_test['dialect_region'].unique())\n",
    "\n",
    "print(f'train_dialects: {train_dialects}')\n",
    "print(f'test_dialects: {test_dialects}')\n",
    "print()\n",
    "print(f'train_dialects & test_dialects: {train_dialects & test_dialects}') # same dialects as in the train set\n",
    "print(f'test_dialects - train_dialects: {test_dialects - train_dialects}') # new dialects in the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, our test set fully consists of new speakers and 6 new dialects, which mean we have to validate our model on dialects and speakers, which were not present during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T19:26:37.788219Z",
     "iopub.status.busy": "2025-04-02T19:26:37.787944Z",
     "iopub.status.idle": "2025-04-02T19:26:37.805261Z",
     "shell.execute_reply": "2025-04-02T19:26:37.804334Z",
     "shell.execute_reply.started": "2025-04-02T19:26:37.788180Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1440, Valid: 240, Test: 1680\n"
     ]
    }
   ],
   "source": [
    "df_train = df_phonemes[\n",
    "    (df_phonemes['test_or_train'] == 'TRAIN') & \\\n",
    "    (df_phonemes['dialect_region'] != 'DR2')\n",
    "    ].copy()\n",
    "\n",
    "df_valid = df_phonemes[\n",
    "    (df_phonemes['test_or_train'] == 'TRAIN') & \\\n",
    "    (df_phonemes['dialect_region'] == 'DR2')\n",
    "    ].copy()\n",
    "\n",
    "df_test = df_phonemes[df_phonemes['test_or_train'] == 'TEST'].copy()\n",
    "\n",
    "\n",
    "print(f\"Train: {len(df_train)}, Valid: {len(df_valid)}, Test: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof of Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T19:26:37.806506Z",
     "iopub.status.busy": "2025-04-02T19:26:37.806261Z",
     "iopub.status.idle": "2025-04-02T19:26:37.818074Z",
     "shell.execute_reply": "2025-04-02T19:26:37.817176Z",
     "shell.execute_reply.started": "2025-04-02T19:26:37.806478Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No overlap between validation and train speaker IDs.\n"
     ]
    }
   ],
   "source": [
    "valid_speakers = set(df_valid['speaker_id'].unique())\n",
    "train_speakers = set(df_train['speaker_id'].unique())\n",
    "\n",
    "overlap = valid_speakers & train_speakers  # Intersection of sets\n",
    "\n",
    "if overlap:\n",
    "    print(\"Overlap found:\", overlap)\n",
    "else:\n",
    "    print(\"No overlap between validation and train speaker IDs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T19:26:37.819588Z",
     "iopub.status.busy": "2025-04-02T19:26:37.819273Z",
     "iopub.status.idle": "2025-04-02T19:26:37.836472Z",
     "shell.execute_reply": "2025-04-02T19:26:37.835467Z",
     "shell.execute_reply.started": "2025-04-02T19:26:37.819545Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No overlap between validation and train dialect regions.\n"
     ]
    }
   ],
   "source": [
    "valid_dialects = set(df_valid['dialect_region'].unique())\n",
    "train_dialects = set(df_train['dialect_region'].unique())\n",
    "\n",
    "overlap = valid_dialects & train_dialects  # Intersection of sets\n",
    "\n",
    "if overlap:\n",
    "    print(\"Overlap found:\", overlap)\n",
    "else:\n",
    "    print(\"No overlap between validation and train dialect regions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T19:26:37.875645Z",
     "iopub.status.busy": "2025-04-02T19:26:37.875409Z",
     "iopub.status.idle": "2025-04-02T19:26:37.909750Z",
     "shell.execute_reply": "2025-04-02T19:26:37.908826Z",
     "shell.execute_reply.started": "2025-04-02T19:26:37.875616Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1440, Valid: 240, Test: 1680\n"
     ]
    }
   ],
   "source": [
    "#  from initial df to create json with each entry as unique sample with its auido/word/phonetics paths\n",
    "\n",
    "df['entry_id'] = df['path_from_data_dir'].str.split('.').str[0]\n",
    "\n",
    "# group by entry_id to retain the corresponding 'test_or_train' and 'dialect_region' label\n",
    "entry_labels = df.groupby('entry_id')[['test_or_train', 'dialect_region']].first()\n",
    "\n",
    "# split based on dialect regions = group split by dialect and speaker as each speaker has only 1 dialect (from stats above)\n",
    "train_entries = entry_labels[(entry_labels['test_or_train'] == \"TRAIN\") & (entry_labels['dialect_region'] != \"DR2\")].index.tolist()\n",
    "valid_entries = entry_labels[(entry_labels['test_or_train'] == \"TRAIN\") & (entry_labels['dialect_region'] == \"DR2\")].index.tolist()\n",
    "test_entries = entry_labels[entry_labels['test_or_train'] == \"TEST\"].index.tolist()\n",
    "\n",
    "#  include entries that have all (audio, phonetic, and word) files\n",
    "train = {key: data[key] for key in train_entries if len(data[key]) == 3}\n",
    "valid = {key: data[key] for key in valid_entries if len(data[key]) == 3}\n",
    "test  = {key: data[key] for key in test_entries if len(data[key]) == 3}  \n",
    "\n",
    "print(f\"Train: {len(train)}, Valid: {len(valid)}, Test: {len(test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dataset_splits = {\n",
    "    \"train\": train,\n",
    "    \"valid\": valid,\n",
    "    \"test\": test\n",
    "}\n",
    "\n",
    "OUTPUT_PATH = 'TIMIT_DATA_SPLIT.json'\n",
    "with open(OUTPUT_PATH, \"w\") as f:\n",
    "    json.dump(dataset_splits, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 212391,
     "sourceId": 471627,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
